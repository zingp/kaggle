{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import os \n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_filenames = os.listdir('data/train')\n",
    "datasetdir = os.path.join('./data')\n",
    "traindir = os.path.join(datasetdir,'train2')\n",
    "testdir = os.path.join(datasetdir,'test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = filter(lambda x:x[:3]=='cat', tran_filenames)\n",
    "train_dog = filter(lambda x:x[:3]=='dog', tran_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(model, image_size, imagedir, save_file):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    dataset = datasets.ImageFolder(imagedir, transforms.Compose([\n",
    "        transforms.RandomResizedCrop(image_size),  #224\n",
    "        transforms.RandomHorizontalFlip(),  # 随机挑一些图镜像翻转\n",
    "        transforms.ToTensor(),\n",
    "        normalize,]))\n",
    "    \n",
    "    batch_size = 32\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=10,\n",
    "        # drop_last=True\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    model.eval() \n",
    "    x_extract = []\n",
    "    y_extract = []\n",
    "    for x, y in loader:\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda()\n",
    "            x_ext = model(x)\n",
    "            x_ext = F.adaptive_avg_pool2d(x_ext, (1,1))\n",
    "            x_extract.append(x_ext.data.cpu().numpy())  # 只有一个Tensor可以转换成numpy\n",
    "            y_extract.append(y.data.numpy())\n",
    "    x_nobatch_ext = np.array([x for item in x_extract for x in item])\n",
    "    y_nobatch_ext = np.array([x for item in y_extract for x in item])\n",
    "    print(\"x shape:\", x_nobatch_ext.shape)\n",
    "    print(\"y sahpe:\", y_nobatch_ext.shape)\n",
    "    np.save(save_file, x_nobatch_ext)\n",
    "    np.save(\"y-{}\".format(save_file), y_nobatch_ext)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "models_dic = {}\n",
    "model1 = nn.Sequential(*list(models.resnet50(pretrained=True).children())[:-2])  # 这里删除最后两层为了和后面的模型统一\n",
    "models_dic[\"resnet50\"] = model1\n",
    "model2 = nn.Sequential(*list(models.densenet161(pretrained=True).children())[:-1]) \n",
    "models_dic[\"densenet161\"] = model2\n",
    "# model3 = nn.Sequential(*list(models.vgg19(pretrained=True).children())[:-1])\n",
    "# models_dic[\"vgg19\"] = model3\n",
    "model4 = nn.Sequential(*list(models.resnet152(pretrained=True).children())[:-2]) \n",
    "models_dic[\"resnet152\"] = model4\n",
    "image_dir = {\n",
    "    \"train_dir\":traindir, \n",
    "    \"test_dir\":testdir\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaveFile: resnet152-train_dir\n",
      "x shape: (25000, 2048, 1, 1)\n",
      "y sahpe: (25000,)\n",
      "Done!\n",
      "SaveFile: resnet152-test_dir\n",
      "x shape: (12500, 2048, 1, 1)\n",
      "y sahpe: (12500,)\n",
      "Done!\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "for m_name, m in models_dic.items():\n",
    "    for d_name,d in image_dir.items():\n",
    "        save_file = \"{}-{}\".format(m_name, d_name)\n",
    "        print(\"SaveFile:\", save_file)\n",
    "        feature_extract(m, image_size=image_size, imagedir=d, save_file=save_file)\n",
    "print(\"All Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_li = [\"densenet161-test_dir.npy\", \"resnet50-test_dir.npy\",\"resnet152-test_dir.npy\"]\n",
    "x_train_li = [\"densenet161-train_dir.npy\",\"resnet50-train_dir.npy\",\"resnet152-train_dir.npy\"]\n",
    "y_train_li = [\"y-densenet161-train_dir.npy\", \"y-resnet50-train_dir.npy\", \"y-resnet152-train_dir.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_dataset(npfiles):\n",
    "    concat_fea = []\n",
    "    for f in npfiles:\n",
    "        np_load = np.load(f)\n",
    "        concat_fea.append(np_load)\n",
    "    concat_fea = np.concatenate(concat_fea, axis=1)\n",
    "    return concat_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = creat_dataset(x_train_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.reshape(X.shape[0],X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t= creat_dataset(x_test_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_t.reshape(X_t.shape[0], X_t.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 6304)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load(y_train_li[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train):\n",
    "    input_tensor = keras.Input(X_train.shape[1:])\n",
    "    x = Dropout(0.5)(input_tensor)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(input_tensor, x)\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 6304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6305      \n",
      "=================================================================\n",
      "Total params: 6,305\n",
      "Trainable params: 6,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/8\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0903 - acc: 0.9669 - val_loss: 0.0238 - val_acc: 0.9928\n",
      "Epoch 2/8\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 0.0294 - acc: 0.9905 - val_loss: 0.0180 - val_acc: 0.9946\n",
      "Epoch 3/8\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 0.0235 - acc: 0.9927 - val_loss: 0.0179 - val_acc: 0.9946\n",
      "Epoch 4/8\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0215 - acc: 0.9925 - val_loss: 0.0239 - val_acc: 0.9916\n",
      "Epoch 5/8\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 0.0211 - acc: 0.9928 - val_loss: 0.0190 - val_acc: 0.9938\n",
      "Epoch 6/8\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0167 - val_acc: 0.9944\n",
      "Epoch 7/8\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0165 - val_acc: 0.9944\n",
      "Epoch 8/8\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 0.0179 - acc: 0.9946 - val_loss: 0.0167 - val_acc: 0.9946\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [os.path.join(testdir, 'test', f) for f in sorted(os.listdir(os.path.join(testdir,'test')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(preds, images, csv_name, clib=False):\n",
    "    if clib:\n",
    "        preds = preds.clip(min=0.005,max=0.995)\n",
    "    pred_result = preds[:, 0]\n",
    "    results = zip(images, pred_result)\n",
    "    idx = [(x[0].split('/')[-1]).split('.')[0] for x in results]\n",
    "    res = pd.DataFrame.from_dict({\n",
    "        'id': idx,\n",
    "        'label': pred_result.tolist()\n",
    "    })\n",
    "    res = res.set_index('id')\n",
    "    res.to_csv(csv_name)\n",
    "    print(\"Save {} done.\".format(csv_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save submission.csv done.\n"
     ]
    }
   ],
   "source": [
    "save_csv(preds, test_images, \"submission.csv\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save submission-trick.csv done.\n"
     ]
    }
   ],
   "source": [
    "save_csv(preds, test_images, \"submission-trick.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feature_extract(model, image_size, imagedir, save_file):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    dataset = datasets.ImageFolder(imagedir, transforms.Compose([\n",
    "        transforms.RandomResizedCrop(image_size),  #224\n",
    "        transforms.RandomHorizontalFlip(),  # 随机挑一些图镜像翻转\n",
    "        transforms.ToTensor(),\n",
    "        normalize,]))\n",
    "    \n",
    "    batch_size = 32\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=10,\n",
    "        # drop_last=True\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    model.eval() \n",
    "    x_extract = []\n",
    "    y_extract = []\n",
    "    for x, y in loader:\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda()\n",
    "            x_ext = model(x)\n",
    "            x_ext = F.adaptive_avg_pool2d(x_ext, (1,1))\n",
    "            x_extract.append(x_ext.data.cpu().numpy())  # 只有一个Tensor可以转换成numpy\n",
    "            y_extract.append(y.data.numpy())\n",
    "            break\n",
    "    x_nobatch_ext = np.array([x for item in x_extract for x in item])\n",
    "    y_nobatch_ext = np.array([x for item in y_extract for x in item])\n",
    "    print(\"x shape:\", x_nobatch_ext.shape)\n",
    "    print(\"y sahpe:\", y_nobatch_ext.shape)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (32, 2048, 1, 1)\n",
      "y sahpe: (32,)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_feature_extract(nn.Sequential(*list(models.resnet50(pretrained=True).children())[:-2]),\n",
    "                image_size=224, imagedir=testdir, save_file=\"xxx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在pytorch 里尝试把最后一层压扁没有成功\n",
    "# https://zhuanlan.zhihu.com/p/25978105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(testdir, transforms.Compose([\n",
    "        transforms.Resize(331),\n",
    "        transforms.CenterCrop(299),   #224\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size = batch_size, \n",
    "    shuffle=False,\n",
    "    num_workers = 10,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
